{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hongnguyen1306/test/blob/master/Copy_of_TS_TCC_23_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/emadeldeen24/TS-TCC.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaQlStJw6qpz",
        "outputId": "cdf54d92-0507-4fd0-ae4d-6b2739578af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TS-TCC'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 148 (delta 46), reused 28 (delta 28), pack-reused 84\u001b[K\n",
            "Receiving objects: 100% (148/148), 2.90 MiB | 23.03 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y83WgcSKQCPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb52f84-513b-494e-db4d-6d3c958202d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne==0.20.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73ObGiij6vsn",
        "outputId": "9ca0f1cc-6a06-4e8b-e2b1-b225538561e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mne==0.20.7\n",
            "  Downloading mne-0.20.7-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.10/dist-packages (from mne==0.20.7) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from mne==0.20.7) (1.10.1)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.20.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# phải dùng pytorch 1.7 thì processing data mới đc\n",
        "!pip install torch==1.7.0 torchvision==0.8.0 torchaudio==0.7.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7sV93OA61lP",
        "outputId": "2598f898-840c-4f9a-eaad-a492156e3158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn\n",
        "!pip install -U numpy\n",
        "!pip install openpyxl\n",
        "!pip install einops\n",
        "!pip install -U pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "0SNe3ffH66Zb",
        "outputId": "36235f31-654e-4ca2-dbee-65dab6de22fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting pandas\n",
            "  Downloading pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/MyCode/TS-TCC/data_preprocessing/sleep-edf/preprocess_sleep_edf.py"
      ],
      "metadata": {
        "id": "iAnO5G-o7GMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/MyCode/TS-TCC/data_preprocessing/sleep-edf/generate_train_val_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsDpWm0OoWKC",
        "outputId": "78252679-84a1-434e-95a7-7dc8ecc70516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "X_train  (97645, 3000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/MyCode/generate.py"
      ],
      "metadata": {
        "id": "t5PpEgRYDzFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96dc97e0-10c0-430a-eb4f-1c98a895c0e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_train 202.0\n",
            "min_train -207.0\n",
            "val_files (24,)\n",
            "data_save torch.Size([123993, 1, 3000])\n",
            "max_val 203.39926\n",
            "min_val -208.0\n",
            "(1273, 3000, 1)\n",
            "(1132, 3000, 1)\n",
            "(952, 3000, 1)\n",
            "(1144, 3000, 1)\n",
            "(1003, 3000, 1)\n",
            "(1274, 3000, 1)\n",
            "(1021, 3000, 1)\n",
            "(1108, 3000, 1)\n",
            "(1597, 3000, 1)\n",
            "(1052, 3000, 1)\n",
            "(1054, 3000, 1)\n",
            "(1560, 3000, 1)\n",
            "(1582, 3000, 1)\n",
            "(824, 3000, 1)\n",
            "(918, 3000, 1)\n",
            "(1195, 3000, 1)\n",
            "(1092, 3000, 1)\n",
            "(1166, 3000, 1)\n",
            "(983, 3000, 1)\n",
            "(1040, 3000, 1)\n",
            "(997, 3000, 1)\n",
            "(1148, 3000, 1)\n",
            "(1237, 3000, 1)\n",
            "(1652, 3000, 1)\n",
            "(1823, 3000, 1)\n",
            "(1063, 3000, 1)\n",
            "(1107, 3000, 1)\n",
            "(1271, 3000, 1)\n",
            "(1413, 3000, 1)\n",
            "(1229, 3000, 1)\n",
            "max_test 206.0\n",
            "min_test -248.0\n",
            "data_savehuhu {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T9KCEoviEZLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/MyCode/TS-TCC/main.py --experiment_description exp9_1 --run_description run_1 --seed 0 --training_mode supervised --selected_dataset sleepEDF"
      ],
      "metadata": {
        "id": "f2NwMZDg-zp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899de967-4830-4416-cf96-ba5108e35e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================================\n",
            "Dataset: sleepEDF\n",
            "Method:  TS-TCC\n",
            "Mode:    supervised\n",
            "=============================================\n",
            "4444444444  <config_files.sleepEDF_Configs.Config object at 0x7f0e06a9a680> supervised\n",
            "train_dataset  <dataloader.dataloader.Load_Dataset object at 0x7f0e06a9b160>\n",
            "Data loaded ...\n",
            "\n",
            " configs \n",
            "Training started ....\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 1\n",
            "Train Loss     : 0.7135\t | \tTrain Accuracy     : 0.7235\n",
            "Valid Loss     : 0.6384\t | \tValid Accuracy     : 0.7668\n",
            "Test loss      : 1.0144\t | \tTest Accuracy      : 0.6947\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 2\n",
            "Train Loss     : 0.6086\t | \tTrain Accuracy     : 0.7658\n",
            "Valid Loss     : 0.6924\t | \tValid Accuracy     : 0.7254\n",
            "Test loss      : 1.0533\t | \tTest Accuracy      : 0.6668\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 3\n",
            "Train Loss     : 0.5801\t | \tTrain Accuracy     : 0.7782\n",
            "Valid Loss     : 0.5968\t | \tValid Accuracy     : 0.7705\n",
            "Test loss      : 1.0668\t | \tTest Accuracy      : 0.6968\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 4\n",
            "Train Loss     : 0.5638\t | \tTrain Accuracy     : 0.7838\n",
            "Valid Loss     : 0.5464\t | \tValid Accuracy     : 0.7969\n",
            "Test loss      : 1.0196\t | \tTest Accuracy      : 0.7073\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 5\n",
            "Train Loss     : 0.5403\t | \tTrain Accuracy     : 0.7935\n",
            "Valid Loss     : 0.5036\t | \tValid Accuracy     : 0.8116\n",
            "Test loss      : 1.0584\t | \tTest Accuracy      : 0.7133\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 6\n",
            "Train Loss     : 0.5304\t | \tTrain Accuracy     : 0.7966\n",
            "Valid Loss     : 0.5244\t | \tValid Accuracy     : 0.8094\n",
            "Test loss      : 1.0346\t | \tTest Accuracy      : 0.7206\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 7\n",
            "Train Loss     : 0.5204\t | \tTrain Accuracy     : 0.8003\n",
            "Valid Loss     : 0.5155\t | \tValid Accuracy     : 0.8072\n",
            "Test loss      : 1.1382\t | \tTest Accuracy      : 0.7067\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 8\n",
            "Train Loss     : 0.5084\t | \tTrain Accuracy     : 0.8046\n",
            "Valid Loss     : 0.5369\t | \tValid Accuracy     : 0.8065\n",
            "Test loss      : 1.1695\t | \tTest Accuracy      : 0.7068\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 9\n",
            "Train Loss     : 0.4982\t | \tTrain Accuracy     : 0.8090\n",
            "Valid Loss     : 0.5991\t | \tValid Accuracy     : 0.7760\n",
            "Test loss      : 1.2340\t | \tTest Accuracy      : 0.6795\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 10\n",
            "Train Loss     : 0.4908\t | \tTrain Accuracy     : 0.8108\n",
            "Valid Loss     : 0.4913\t | \tValid Accuracy     : 0.8169\n",
            "Test loss      : 1.3158\t | \tTest Accuracy      : 0.7020\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 11\n",
            "Train Loss     : 0.4789\t | \tTrain Accuracy     : 0.8152\n",
            "Valid Loss     : 0.5070\t | \tValid Accuracy     : 0.8138\n",
            "Test loss      : 1.3774\t | \tTest Accuracy      : 0.7073\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 12\n",
            "Train Loss     : 0.4733\t | \tTrain Accuracy     : 0.8187\n",
            "Valid Loss     : 0.5051\t | \tValid Accuracy     : 0.8111\n",
            "Test loss      : 1.3307\t | \tTest Accuracy      : 0.6989\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 13\n",
            "Train Loss     : 0.4675\t | \tTrain Accuracy     : 0.8207\n",
            "Valid Loss     : 0.4883\t | \tValid Accuracy     : 0.8170\n",
            "Test loss      : 1.4910\t | \tTest Accuracy      : 0.6693\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 14\n",
            "Train Loss     : 0.4540\t | \tTrain Accuracy     : 0.8253\n",
            "Valid Loss     : 0.5554\t | \tValid Accuracy     : 0.7892\n",
            "Test loss      : 1.7235\t | \tTest Accuracy      : 0.6438\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 15\n",
            "Train Loss     : 0.4465\t | \tTrain Accuracy     : 0.8293\n",
            "Valid Loss     : 0.5095\t | \tValid Accuracy     : 0.8183\n",
            "Test loss      : 1.5191\t | \tTest Accuracy      : 0.6972\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 16\n",
            "Train Loss     : 0.4424\t | \tTrain Accuracy     : 0.8294\n",
            "Valid Loss     : 0.5090\t | \tValid Accuracy     : 0.8096\n",
            "Test loss      : 1.5943\t | \tTest Accuracy      : 0.6759\n",
            "======================    Haven't Training yet    ====================\n",
            "\n",
            "\n",
            "Epoch : 17\n",
            "Train Loss     : 0.4354\t | \tTrain Accuracy     : 0.8327\n",
            "Valid Loss     : 0.4955\t | \tValid Accuracy     : 0.8165\n",
            "Test loss      : 1.3590\t | \tTest Accuracy      : 0.6941\n",
            "======================    Haven't Training yet    ====================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/MyCode/TS-TCC/test.py --experiment_description exp --run_description run_1 --seed 123 --training_mode supervised --selected_dataset sleepEDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "324jqmjFU428",
        "outputId": "1f11221a-884e-479f-88a6-9d31fbc552b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============================================\n",
            "Dataset: sleepEDF\n",
            "Mode:    supervised\n",
            "Activate:    nn.GeLU() epoch 30\n",
            "=============================================\n",
            "4444444444  <config_files.sleepEDF_Configs.Config object at 0x7f0df91efb50> supervised\n",
            "train_dataset  <dataloader.dataloader.Load_Dataset object at 0x7f0df9224340>\n",
            "Data loaded ...\n",
            "The model will be running on cuda:0 device\n",
            "\n",
            "\n",
            "outs  [2. 4. 2. 2. 2. 2. 1. 2. 2. 2. 4. 2. 0. 2. 2. 2. 2. 1. 0. 2. 1. 2. 4. 3.\n",
            " 2. 2. 2. 1. 2. 2. 4. 2. 2. 1. 2. 4. 1. 2. 2. 1. 2. 2. 2. 0. 0. 0. 2. 2.\n",
            " 2. 2. 0. 2. 1. 4. 2. 2. 2. 1. 2. 2. 1. 2. 1. 1. 2. 2. 2. 1. 2. 1. 2. 0.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 0. 2. 1. 1. 1. 2. 1. 1. 2. 2. 2.\n",
            " 2. 0. 0. 2. 2. 2. 4. 0. 4. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 2. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 2. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            " 4. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 4. 1. 1. 1. 4. 4. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 3. 3. 2. 2. 2. 3. 2. 2. 2. 2. 3. 3.\n",
            " 3. 2. 3. 3. 2. 2. 0. 0. 0. 2. 0. 0. 1. 4. 4. 2. 4. 2. 2. 2. 2. 0. 0. 2.\n",
            " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 4.\n",
            " 4. 4. 0. 4. 4. 1. 4. 1. 0. 1. 1. 4. 0. 4. 4. 1. 4. 4. 4. 4. 0. 0. 4. 0.\n",
            " 4. 0. 0. 4. 4. 0. 4. 4. 4. 0. 1. 1. 4. 4. 2. 2. 4. 2. 2. 2. 2. 2. 0. 2.\n",
            " 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 2. 2. 1. 4. 2. 2. 2. 2. 2. 0. 2. 4. 2. 2. 2.\n",
            " 2. 2. 2. 4. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 4. 0. 1. 0. 0. 0. 1. 4. 0. 4. 4. 4. 0. 4.\n",
            " 4. 4. 0. 4. 0. 4. 4. 4. 2. 4. 4. 4. 4. 4. 2. 4. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 4. 2. 2. 4. 2. 2. 4. 2. 2. 4. 2. 2. 2. 2. 4. 2. 2. 2. 4. 4. 4. 2. 2. 4.\n",
            " 2. 2. 2. 2. 2. 2. 0. 3. 2. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 3. 3. 0. 2. 2. 2. 2. 2. 2. 0. 0. 1. 1. 1. 2. 0. 0. 2. 2. 2.\n",
            " 0. 2. 2. 2. 2. 0. 2. 2. 2. 1. 1. 2. 0. 0. 0. 2. 1. 1. 0. 0. 2. 0. 0. 4.\n",
            " 4. 1. 2. 2. 4. 1. 4. 2. 4. 2. 2. 2. 4. 2. 2. 2. 0. 1. 4. 0. 4. 1. 1. 0.\n",
            " 0. 0. 1. 4. 4. 1. 4. 0. 4. 0. 4. 2. 0. 2. 4. 2. 2. 4. 1. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 1. 2. 2. 2.\n",
            " 2. 2. 2. 0. 3. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 2. 3. 3. 2. 3. 2. 2. 2. 2.\n",
            " 2. 2. 2. 3. 1. 3. 4. 2. 2. 2. 0. 2. 0. 4. 0. 1. 2. 2. 4. 2. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 0. 4. 4. 4. 0. 4. 0. 0. 4. 1. 4. 4. 0. 0. 4. 1. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 0. 4. 4. 1. 4. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 4.\n",
            " 4. 1. 0. 1. 4. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 1. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 4. 4. 0. 4. 0. 0. 4. 4. 0.\n",
            " 4. 4. 0. 0. 4. 0. 4. 4. 4. 4. 4. 0. 4. 4. 1. 4. 4. 2. 0. 1. 4. 0. 0. 1.\n",
            " 4. 0. 4. 1. 1. 1. 4. 0. 4. 4. 0. 2. 0. 1. 4. 0. 4. 0. 4. 4. 0. 4. 0. 0.\n",
            " 4. 4. 0. 0. 4. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 2. 2.\n",
            " 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 4. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 1. 4. 2. 2. 2. 0. 1. 1. 2. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 2. 2. 2. 2. 0. 2. 1. 2. 2. 2. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 1. 4. 4. 4. 4. 4. 4. 4. 4. 0. 1. 0. 4. 4. 4. 4. 1. 4. 0. 0. 0. 4. 0. 4.\n",
            " 4. 1. 4. 2. 4. 2. 4. 2. 2. 4. 4. 4. 4. 2. 2. 2. 4. 2. 2. 4. 2. 2. 2. 4.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 4. 2. 2. 1. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 2. 4. 4. 2. 2. 2. 2. 4. 4. 2. 4. 2. 4. 2. 1. 0. 0. 0. 0. 2. 0. 2. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 2. 0. 0. 0. 2. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 4. 0. 0. 4.\n",
            " 0. 0.]\n",
            "\n",
            "trgs  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 2. 3. 2. 2. 2.\n",
            " 3. 2. 2. 3. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 2. 3.\n",
            " 3. 3. 2. 2. 3. 3. 3. 3. 3. 3. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
            " 3. 3. 3. 3. 3. 2. 0. 0. 0. 2. 0. 0. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 0. 0. 4. 4. 4. 4. 4. 4. 2. 2. 4. 4. 4. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 0. 0. 0. 0. 0. 0. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 0. 0. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 3. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 2. 3. 3. 2. 3. 2. 2. 2. 2.\n",
            " 2. 2. 2. 3. 3. 3. 2. 2. 2. 2. 2. 2. 2. 2. 0. 1. 2. 2. 2. 2. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 4.\n",
            " 4. 4. 4. 4. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 2. 2.\n",
            " 2. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3.\n",
            " 0. 0. 0. 0. 0. 0. 1. 1. 2. 2. 2. 2. 2. 0. 1. 1. 2. 2. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 2. 2. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "\n",
            " total_acc  tensor(0.6998) \ttotal_loss  tensor(1.0302)\n",
            "Nhãn 0: Tỉ lệ dự đoán đúng = 0.6861702127659575\n",
            "Nhãn 1: Tỉ lệ dự đoán đúng = 0.7777777777777778\n",
            "Nhãn 2: Tỉ lệ dự đoán đúng = 0.8870967741935484\n",
            "Nhãn 3: Tỉ lệ dự đoán đúng = 0.3333333333333333\n",
            "Nhãn 4: Tỉ lệ dự đoán đúng = 0.5210843373493976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/MyCode/TS-TCC/main.py --experiment_description exp8 --run_description run_1 --seed 123 --training_mode fine_tune --selected_dataset sleepEDF"
      ],
      "metadata": {
        "id": "anwMz1wvoFRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.summary.event_accumulator import EventAccumulator\n",
        "\n",
        "event_acc = EventAccumulator('/content/drive/MyDrive/deepsleepnet_tensor1x/output/fold0/deepsleepnet/train_summary/events.out.tfevents.1681281587.0181d5aaa139')\n",
        "event_acc.Reload()\n",
        "\n",
        "# Xem tất cả các tags trong file events\n",
        "tags = event_acc.Tags()\n",
        "print(tags)\n",
        "\n",
        "# Lấy giá trị scalar từ file events với tag 'loss'\n",
        "loss = event_acc.Scalars('loss')\n",
        "for scalar in loss:\n",
        "    print(scalar.step, scalar.value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "Y4QxOoBDdlFn",
        "outputId": "478987e7-c140-47bc-d3d4-53a724b2d572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-549561853fff>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_accumulator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEventAccumulator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mevent_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEventAccumulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/deepsleepnet_tensor1x/output/fold0/deepsleepnet/train_summary/events.out.tfevents.1681281587.0181d5aaa139'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevent_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.summary.event_accumulator'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGVWuJ_qeiT3",
        "outputId": "d6125586-7059-40cc-a74d-86f944546354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.22.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.40.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.54.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=events.out.tfevents.1681281587.0181d5aaa139"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGcxIQzmeOMx",
        "outputId": "32c9f373-1349-4bd3-ff74-543158b3d4ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-30 14:09:53.414592: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
            "Exception in thread Reloader:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/backend/event_processing/data_ingester.py\", line 104, in _reload\n",
            "    self._multiplexer.AddRunsFromDirectory(path, name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/backend/event_processing/plugin_event_multiplexer.py\", line 205, in AddRunsFromDirectory\n",
            "    for subdir in io_wrapper.GetLogdirSubdirectories(path):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/backend/event_processing/io_wrapper.py\", line 200, in GetLogdirSubdirectories\n",
            "    raise ValueError(\n",
            "ValueError: GetLogdirSubdirectories: path exists and is not a directory, /content/drive/MyDrive/deepsleepnet_tensor1x/output/fold0/deepsleepnet/train_summary/events.out.tfevents.1681281587.0181d5aaa139\n",
            "TensorBoard 2.12.2 at http://57b7aa958141:6006/ (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load data from npz file\n",
        "data = np.load('/content/drive/MyDrive/deepsleepnet_tensor1x/output/output_subject0.npz')\n",
        "# # train_f1 = data['train_f1']\n",
        "# # train_loss = data['train_loss']\n",
        "# # y_true_val = data['y_true_val']\n",
        "# # valid_loss = data['valid_loss']\n",
        "# # valid_f1 = data['valid_f1']\n",
        "# # y_pred_val = data['y_pred_val']\n",
        "# train_acc = data['train_acc']\n",
        "# valid_acc = data['valid_acc']\n",
        "\n",
        "# # View the contents of the file\n",
        "# df = pd.DataFrame({\n",
        "#     # 'train_f1': train_f1,\n",
        "#     # 'train_loss': train_loss,\n",
        "#     # 'y_true_val': y_true_val,\n",
        "#     # 'valid_loss': valid_loss,\n",
        "#     # 'valid_f1': valid_f1,\n",
        "#     # 'y_pred_val': y_pred_val,\n",
        "#     'train_acc': train_acc,\n",
        "#     'valid_acc': valid_acc\n",
        "# })\n",
        "# # Write data to CSV file\n",
        "# df.to_csv('per0_deepsleepnet_3.csv', index=False)\n",
        "print(data.files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lD2XOqKxtN3_",
        "outputId": "a259a9ce-3416-4450-bb1d-7efa087185ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['y_pred', 'fw_memory_cells', 'y_true', 'bw_memory_cells']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqFxm-hrwn9k",
        "outputId": "3f8f3cd2-92a9-4c42-9b70-1f0edd6cc622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/MyTinysleepnet/out_sleepedf/train/1/checkpoint/checkpoint'\n",
        "\n",
        "# Liệt kê tất cả các biến được lưu trong file checkpoint\n",
        "variables = tf.train.list_variables(checkpoint_path)\n",
        "for var in variables:\n",
        "    print(var)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "8cqkTye1wmEi",
        "outputId": "55be0742-6eec-4dde-8399-f0f55c812e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DataLossError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unable to open table file /content/drive/MyDrive/MyTinysleepnet/out_sleepedf/train/1/checkpoint/checkpoint: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mDataLossError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-7bcf986d50b1>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Liệt kê tất cả các biến được lưu trong file checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/checkpoint_utils.py\u001b[0m in \u001b[0;36mlist_variables\u001b[0;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m   \"\"\"\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_dir_or_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m   \u001b[0mvariable_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_to_shape_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m   \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/checkpoint_utils.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[1;32m     78\u001b[0m     raise ValueError(\"Couldn't find 'checkpoint' file or checkpoints in \"\n\u001b[1;32m     79\u001b[0m                      \"given directory %s\" % ckpt_dir_or_file)\n\u001b[0;32m---> 80\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;31m# issue with throwing python exceptions from C++.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0merror_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;34m'Unable to open table file'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLossError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m   elif 'Failed to find the saved tensor slices' in error_message or (\n\u001b[1;32m     42\u001b[0m       'not convertible to numpy dtype' in error_message):\n",
            "\u001b[0;31mDataLossError\u001b[0m: Unable to open table file /content/drive/MyDrive/MyTinysleepnet/out_sleepedf/train/1/checkpoint/checkpoint: DATA_LOSS: not an sstable (bad magic number): perhaps your file is in a different file format and you need to use a different restore operator?"
          ]
        }
      ]
    }
  ]
}